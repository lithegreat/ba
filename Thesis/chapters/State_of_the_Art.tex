The integration of custom instruction sets within application-specific instruction set processors (ASIPs) has become increasingly vital for enhancing performance in specialized applications, particularly in artificial intelligence (AI) and embedded systems. Recent studies underscore the importance of these custom instruction sets in addressing performance bottlenecks associated with memory access, which is critical for efficient operation in systems such as Deep Neural Networks (DNNs).

The work by Oh and Lee (2023) highlights the role of customizable instruction set architectures (ISAs) in reducing communication overhead and improving energy efficiency by integrating AI processors within general-purpose processors (GPPs) \cite{oh2023design}. This seamless integration allows for significant enhancements in throughput while minimizing the complexity typically associated with heterogeneous computing systems.

Kumar et al. (2024) further contribute to this discussion by exploring an ISA extension for RISC-V focused on optimizing memory load and store operationsâ€”key operations in many embedded applications, especially those involving DNNs. Their study demonstrates a novel instruction that allows for double-word memory access, resulting in substantial reductions in clock cycles (approximately 50\%) and power consumption (around 30\%) during these operations, while maintaining only a minimal area overhead of about 4\% on a modified RISC-V platform. This work validates the need for efficient memory interaction to mitigate power demands and latency, particularly in edge-AI applications where resource constraints are prevalent \cite{kumar2024implementation}.

Salim et al. (2012) also provide valuable insights into the effectiveness of custom instruction sets in RISC processors. Their research illustrates how modifying instruction set architectures can enhance the flexibility and capabilities of embedded systems, reinforcing the necessity of addressing memory organization and physical address remapping to optimize performance \cite{salim2012customized}.

In light of these advancements, our study utilizes the OpenASIP 2.0 Co-Design toolchain to evaluate custom operations within the CoreDSL ecosystem. By translating OpenASIP custom operations into CoreDSL syntax and leveraging the Extendable Translating Instruction Set Simulator (ETISS), we benchmark the performance of these operations against MLonMCU benchmarks. The results indicate a promising moderate speedup, underscoring the potential of custom instruction sets to improve performance in modern embedded applications, akin to the benefits highlighted in the aforementioned research. This approach not only extends the current understanding of custom instruction integration but also provides a foundation for further exploration in the realm of performance optimization for specialized processors.