\section{RISC-V ISA and Extensions}

The RISC-V instruction set architecture (ISA) is an open and modular standard that provides a simplified, extensible foundation for a wide range of computing applications. Its modularity is one of its most significant features, allowing users to start with a small set of base instructions and then tailor the ISA with custom extensions, making it particularly suitable for specialized domains such as edge computing and artificial intelligence.

At its core, the RISC-V base ISA includes only the essential integer arithmetic instructions, such as load/store, branch, and basic arithmetic operations. These instructions form the basis of the RV32I subset, which operates on 32-bit data and provides all the necessary functionalities to execute fundamental computing tasks. The RV32I set consists of 47 instructions encoded in a fixed 32-bit format, with fields specifying operation types, operand registers, and immediate values, as shown in Fig.~\ref{fig:riscvisa}. The opcode is a key part of this encoding, determining the nature of the operation, while other fields like funct3 and funct7 define more specific operations or variations of the base instruction.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/riscvisa.png}
    \caption{RISC-V 32-bit instruction encoding format \cite{RISCVISA}}
    \label{fig:riscvisa}
\end{figure}

The 32-bit encoding format allows for compact and efficient instruction decoding and execution, which is one of the key advantages of RISC-V in embedded systems and low-power applications. Each instruction is defined by specific bit fields (Table~\ref{tab:riscvfields}) \cite{RISCVISA}

\begin{table}[!h]
    \footnotesize
    \centering
    \begin{tabular}{|c|l|}
        \hline
        \textbf{Field} & \textbf{Description} \\
        \hline
        Opcode & Specifies the instruction type, such as arithmetic, memory access, or control flow. \\
        \hline
        rd & Destination register for the result. \\
        \hline
        funct3 & Further categorizes the instruction within the opcode type. \\
        \hline
        rs1 and rs2 & Source registers. \\
        \hline
        funct7 & Provides additional specificity for certain operations, such as shifts and bitwise operations. \\
        \hline
        imm & Immediate value for the instruction. \\
        \hline
    \end{tabular}
    \caption{RISC-V instruction fields}
    \label{tab:riscvfields}

\end{table}

As demonstrated in Table~\ref{fig:opcodemap}, the opcode map for RV32G and RV64G allocates specific major opcodes for standard and custom instruction sets. Custom instructions, denoted by \textbf{custom-0}, \textbf{custom-1}, and others, are reserved for extensions within the 32-bit instruction format. For example, the major opcodes marked as \textbf{custom-2} and \textbf{custom-3} are reserved for future use in RV128, ensuring extensibility for broader data paths.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/opcodemap.png}
    \caption{RISC-V opcode map \cite{RISCVISA}}
    \label{fig:opcodemap}
\end{figure}

RISC-V's open standard encourages customization, allowing for the addition of custom instructions to enhance performance in domain-specific tasks. These custom instructions are often introduced as extensions to the RV32I base, with additional opcode spaces reserved.

In this thesis, custom instructions are designed to accelerate model evaluation in the MLonMCU framework. By targeting key operations in machine learning models, the custom instructions improve the efficiency of critical tasks, leading to substantial performance gains on constrained devices. The flexibility of RISC-V's ISA and its support for custom extensions make it an ideal platform for exploring novel instruction sets tailored to specific applications.

\section{OpenASIP and TTA}

OpenASIP is an open-source co-design toolset that enables the customization of application-specific instruction-set processors (ASIPs) based on the RISC-V architecture. It simplifies the process of adding custom instructions to a processor by generating both the hardware and corresponding software toolchain from a high-level architecture definition (Fig.~\ref{fig:openasip}). This flexibility makes OpenASIP ideal for applications requiring specific optimizations, such as cryptographic algorithms.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/openasip.png}
    \caption{Processor customization flow in OpenASIP \cite{OpenASIP}}
    \label{fig:openasip}
\end{figure}

In recent case studies on AES, CRC, and SHA, custom instructions generated by OpenASIP achieved a 44\% average reduction in runtime, with only a 1.5\% increase in area overhead compared to a standard RV32IM processor \cite{OpenASIP}. The toolset supports both HDL snippets and DAG-based operation descriptions, making it adaptable to various design requirements.

\subsection{Transport Triggered Architecture (TTA)}

OpenASIP supports TTA, a processor architecture that shifts control from operations to data transport. Transport Triggered Architecture (TTA) shifts the focus from executing operations to controlling data transport between functional units. Unlike traditional operation-triggered architectures (OTA), where instructions trigger specific operations, TTA instructions specify data movements, and these movements trigger the operations.

In TTA, the compiler explicitly controls the data flow, moving operands to functional units and transporting results back to registers. For example, an addition `r4 = r2 + r3` is broken down into three transport instructions: moving `r2` and `r3` to the functional unit and then moving the result to `r4`.

The key difference from OTA is that TTA gives the compiler full control over scheduling and optimization, reducing the complexity of hardware control logic. This flexibility allows for optimizations such as bypassing registers, eliminating dead results, and improving execution efficiency.

TTA's advantages include increased scheduling freedom and more efficient data transport, as the compiler can optimize instruction order and resource usage. This results in faster execution and lower hardware complexity, making TTA suitable for customizable, application-specific processors \cite{hoogerbrugge1994transport}.


\section{CoreDSL}

CoreDSL is an open-source language designed to facilitate ISA development for non-experts, such as embedded software engineers. It serves as the entry point of the ISA design toolchain, focusing on creating user-friendly and portable instruction set descriptions. The language's syntax is familiar to engineers accustomed to C and assembly programming, making it accessible and intuitive.

CoreDSL is tailored for describing ISAs with a concise syntax for architectural states, instruction metadata, and behavior. It allows users to describe bit-level manipulations and arithmetic operations in a behavioral, hardware-synthesis-friendly manner, supporting efficient and customizable processor designs. One of its unique features is its capability to express longer-running behaviors and custom control flows, enabling decoupled execution of instructions alongside the main pipeline.

The type system of CoreDSL is centered around signed and unsigned integers of arbitrary bitwidths, and it strictly enforces type safety, reducing the risk of errors when working with small integer types. Furthermore, CoreDSL supports complex ISA implementations through novel constructs like `always` and `spawn`, which allow for decoupled execution, enabling out-of-order-like behavior even for in-order cores. The language is fully open-source and designed to integrate into a vendor-independent, RISC-V-based ecosystem, making it highly adaptable for custom processor extensions \cite{CoreDSL}.

\section{ETISS}
The ETISS is a versatile tool designed for the efficient simulation of embedded systems, particularly those based on RISC architecture. ETISS serves as a bridge between software development and hardware prototyping, allowing developers to test and validate software on virtual prototypes (VPs) before deployment on actual hardware. The primary goals of ETISS include enhancing simulation speed through dynamic binary translation, supporting extensibility to accommodate various instruction sets and architectural features, and providing an interface for integrating with model-driven development processes.

ETISS boasts several notable features that distinguish it from traditional instruction set simulators. Firstly, it utilizes dynamic binary translation, employing Just-In-Time (JIT) compilation to convert target architecture instructions into host architecture instructions on-the-fly, optimizing execution speed. Secondly, the architecture of ETISS is designed to be extendable, allowing users to easily add custom instructions and functionalities. Additionally, ETISS supports Model-Driven Architecture (MDA) principles, enabling seamless code generation and simulation workflows from higher-level models.

The architecture of ETISS is structured to facilitate efficient instruction translation and execution, consisting of several components : an Instruction Fetch Unit that fetches instructions from memory, a Decoder that translates fetched instructions into an internal representation for execution, an Execution Engine that executes the translated instructions, leveraging host architecture capabilities, and a Cache Mechanism that employs caching strategies to store frequently executed instruction sequences, significantly improving performance.

\section{M2-ISA-R}
M2-ISA-R is a framework designed to facilitate the description and implementation of custom ISAs. It uses a metamodel-based approach that allows for a high level of abstraction when specifying both functional and structural components of a processor architecture. This flexibility in modeling makes it particularly useful for hardware-software co-design.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/m2isar.png}
    \caption{M2-ISA-R workflow \cite{RISCVSimulation}}
    \label{fig:m2isar}
\end{figure}

The workflow (Fig.~\ref{fig:m2isar}) of M2-ISA-R involves parsing the ISA description via a frontend that utilizes the ANTLR4 framework. It then generates Python-based metamodel classes to capture both the architectural and behavioral aspects of the processor. The backend produces architecture-specific plugins for simulation tools, the most important of which is the ETISS architecture plugin. This enables rapid creation of CPU models for ETISS, closing the gap between high-level ISA descriptions and functional simulation.

In this research, M2-ISA-R has been employed to automatically generate the ETISS CPU architecture plugin for a custom ISA, allowing the seamless integration of this architecture into the ETISS simulation framework. This significantly reduces the development time needed for functional verification and performance simulation of custom CPU designs \cite{RISCVSimulation}.

\section{LLVM}

LLVM (Low-Level Virtual Machine) is a versatile compiler infrastructure that supports the compilation of various programming languages to multiple target architectures. Its architecture consists of a collection of reusable compiler and toolchain technologies, providing a robust framework for both frontend and backend development.

At its core, LLVM employs an intermediate representation (IR) that serves as a common code representation between source languages and target architectures. This IR is designed to be language-agnostic and can be optimized independently of the source code, enabling a wide range of optimization techniques to be applied uniformly across different languages.

One of the key features of LLVM is its modularity, which allows developers to extend the compiler with new optimizations or target architectures without modifying existing components. This flexibility is particularly advantageous for research and development in custom instruction sets, facilitating rapid prototyping and experimentation.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/llvm.png}
    \caption{LLVM compilation process. \cite{llvmfigure}}
    \label{fig:llvm}
\end{figure}

The compilation process in LLVM (See Fig.~\ref{fig:llvm}) typically comprises several stages:

\begin{enumerate}
    \item \textbf{Frontend:} This component parses the source code and converts it into LLVM IR. Frontends can be developed for various programming languages, allowing LLVM to serve as a backend for diverse ecosystems.

    \item \textbf{Optimization:} Once in IR form, LLVM applies a series of optimization passes that enhance performance, reduce code size, and improve overall efficiency. These optimizations can be tailored based on the specific characteristics of the target architecture.

    \item \textbf{Backend:} The backend is responsible for generating machine code specific to the target architecture. It leverages target-specific information to produce optimized and efficient binaries.
\end{enumerate}

In the context of custom instruction sets, LLVM's design allows for seamless integration of vendor-defined extensions. By defining new instruction patterns and leveraging existing optimization frameworks, developers can enhance the performance of their applications without requiring deep knowledge of the underlying compiler infrastructure \cite{llvm}.

\section{Seal5}

This work builds upon the Seal5 framework (Fig.~\ref{fig:seal5}), which provides a semi-automated flow for generating LLVM compiler support for custom RISC-V instruction set architectures (ISAs). Seal5 leverages a C-style ISA description language to facilitate the integration of vendor-defined instructions, allowing for efficient exploration and implementation of custom instructions tailored to specific applications.

Seal5 enables the automatic generation of LLVM patches that cover a wide range of functionalities, from baseline assembly-level support to sophisticated compiler code generation patterns for scalar and vector instructions . The tool features a novel pattern generator approach focused on optimizing code generation for SIMD (Single Instruction, Multiple Data) instructions, including autovectorization capabilities.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/seal5.png}
    \caption{Seal5 workflow \cite{Seal5}}
    \label{fig:seal5}
\end{figure}

By utilizing Seal5, this research aims to convert a custom instruction set into a customized LLVM backend. This process significantly reduces development time and effort while achieving performance levels comparable to or exceeding those of manually implemented LLVM toolchains. The ability of Seal5 to support autovectorization enhances the execution efficiency of workloads, making it an invaluable asset for the exploration of custom ISA extensions \cite{Seal5}.

\section{MLonMCU}
MLonMCU is a benchmarking tool designed specifically for TinyML applications, enabling extensive performance evaluations across various models, frameworks, and hardware platforms. It is a flexible, framework-independent solution that allows for rapid retargeting to different platforms and devices. MLonMCU supports multiple TinyML frameworks, including TensorFlow Lite for Microcontrollers (TFLM) and MicroTVM, among others, offering a unified interface to compare the performance of machine learning models on embedded devices.

Key design principles of MLonMCU include isolation, reproducibility, parallelism, and extensibility. The tool isolates dependencies across different environments, ensuring that benchmarking sessions are not affected by other processes running on the system. It allows users to access all intermediate artifacts generated during a benchmarking session, ensuring full reproducibility of results. Furthermore, MLonMCU makes use of all available computational resources to run benchmarks in parallel, significantly speeding up the evaluation process. It also provides an extensible API, allowing users to integrate custom components and features easily.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/MLonMCUStructureNew.pdf}
    \caption{MLonMCU workflow \cite{MLonMCU}}
    \label{fig:mlonmcu}
\end{figure}

MLonMCU's workflow (Fig.~\ref{fig:mlonmcu}) consists of several stages, including model loading, compilation, and execution on target devices or simulators. It also supports post-processing stages for result analysis, where it generates detailed reports on metrics such as execution latency, instructions per cycle, runtime, and memory usage. The platform-agnostic design of MLonMCU ensures that it can handle a wide variety of devices out of the box, making it an ideal tool for early-stage design evaluations and virtual prototyping.

In this research, MLonMCU is used to evaluate the performance of translated instruction sets across different machine learning models. The benchmarking results provide crucial insights into how well the custom instruction sets perform in terms of execution efficiency and resource usage across various target platforms \cite{MLonMCU}.