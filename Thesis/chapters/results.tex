\section{Translated Instructions}

\begin{table}[!ht]
    \small
    \centering
    \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{name} & \textbf{description} \\ \hline
    SHL1ADD & Array indexing for 16-bit data types \\ \hline
    SHL2ADD & Array indexing for 32-bit data types \\ \hline
    ADD & Integer addition.  \\ \hline
    SUB & Integer subtraction.  \\ \hline
    EQ & Equality comparison.  \\ \hline
    GT & Greater-than signed integer comparison.  \\ \hline
    GTU & Greater-than unsigned integer comparison.  \\ \hline
    LT & Less-than signed integer comparison. \\ \hline
    LTU & Less-than unsigned integer comparison. \\ \hline
    NE & Not equal signed integer comparison. \\ \hline
    GE & Greater or equal signed integer comparison. \\ \hline
    GEU & Greater or equal unsigned integer comparison. \\ \hline
    LE & Less or equal signed integer comparison. \\ \hline
    LEU & Less or equal unsigned integer comparison. \\ \hline
    SHL & Left logical shift. \\ \hline
    SHR & Arithmetic shift right (sign bit duplicated). \\ \hline
    SHRU & Logical shift right (most significant bits zeroed). \\ \hline
    AND & Bitwise AND.  \\ \hline
    IOR & Inclusive OR.  \\ \hline
    XOR & Exclusive OR.  \\ \hline
    MIN & Returns the smaller of the two signed integer values.  \\ \hline
    MAX & Returns the larger of the two signed input values.  \\ \hline
    MINU & Returns the smaller of the two unsigned input values. \\ \hline
    MAXU & Returns the larger of the two unsigned input values. \\ \hline
    MUL & 32-bit integer multiplication of the inputs 1 and 2 with lower result bits in the output 3. \\ \hline
    MULHI & 32-bit integer multiplication of the signed inputs 1 and 2 with higher result bits in the output 3. \\ \hline
    MULHIU & 32-bit integer multiplication of the unsigned inputs 1 and 2 with higher result bits in the output 3. \\ \hline
    MULHISU & 32-bit integer multiplication of the signed input 1 and unsigned input 2 with higher result bits in the output 3. \\ \hline
    DIV & Integer division. \\ \hline
    DIVU & Unsigned integer division. \\ \hline
    MAC & Multiply and accumulate (signed integer). \\ \hline
    ROTL & Rotate left. \\ \hline
    ROTR & Rotate right. \\ \hline
    MOD & Integer modulo. \\ \hline
    REM & Integer remainder. \\ \hline
    MODU & Integer modulo (unsigned). \\ \hline
    REMU & Integer remainder (unsigned). \\ \hline
    ANDN & Does a bitwise negation (NOT) on the 2nd input followed by AND of the 1st input and the negated 2nd output. Special instruction in TI C64X. \\ \hline
    SELECT & Select one of two values. \\ \hline
    \end{tabularx}
    \caption{Translated Instruction Set Table}
    \label{tab:translated_instructions}
\end{table}

40 custom instructions were translated from OpenASIP to CoreDSL and integrated into the MLonMCU benchmarking framework. These custom instructions were then evaluated across various machine learning models to assess their impact on performance. The results of the benchmarking process are summarized in the Table~\ref{tab:translated_instructions}.

\section{Setup}

The custom instructions from OpenASIP were first translated into CoreDSL syntax, as discussed in the previous chapter. Using the Seal5 framework, these CoreDSL representations were transformed into LLVM intermediate representations (IR). This LLVM IR was then integrated into the MLonMCU benchmarking framework, allowing seamless execution on the ETISS instruction set simulator (ISS). The MLonMCU use the LLVM backend generated by Seal5 to compile the benchmark models into machine code, which is then executed on the ETISS simulator.

The setup enables testing of various benchmark models across different machine learning domains, such as image processing, time-series analysis, and natural language processing. The list of evaluated models includes \textbf{cifar10}, \textbf{coremark}, \textbf{lstm2}, \textbf{magic\_wand}, \textbf{micro\_kws\_m\_fp32}, \textbf{simple\_mnist}, \textbf{sine\_model}, \textbf{text\_class}, and \textbf{umatest}.

After testing the models, the performance metrics were collected, including the total number of instructions executed, ROM and RAM usage, and the number of clock cycles relative to the baseline configuration. These metrics were filtered and analysed by a custom script to evaluate the impact of the custom instructions on performance.

By evaluating these diverse models, the performance of the custom instructions was assessed in a variety of real-world applications, providing insights into their potential benefits across different computational domains, such as image processing, time-series analysis, and natural language processing.

\section{Performance}

The performance evaluation of the system focuses on several important metrics: the total number of instructions executed, ROM and RAM usage, and clock cycles in comparison to the baseline configuration. Table~\ref{tab:performance_metrics} provides a comprehensive overview of these metrics for different models, highlighting the impact of introducing custom instructions on the overall performance.


\begin{table}[!ht]
    \scriptsize
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|}
        \hline
        {\textbf{Model}} & \multicolumn{3}{c|}{\textbf{Baseline}} & \multicolumn{3}{c|}{\textbf{Custom Instructions}} \\
        \cline{2-7}
        & \textbf{Instructions} & \textbf{ROM} & \textbf{RAM} & \textbf{Instructions} & \textbf{ROM} & \textbf{RAM} \\
        \hline
        {\textbf{coremark}} & 3,877,413 & 50,136 & 4,796 & 3,805,676 \textbf{(-2\%)} & 50,120 \textbf{\textbf{($\simeq$)}} & 4,796 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{magic\_wand}} & 267,505 & 66,728 & 19,148 & 267,804 \textbf{\textbf{($\simeq$)}} & 66,744 \textbf{\textbf{($\simeq$)}} & 19,148 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{micro\_kws\_m\_fp32}} & 18,279,566 & 163,816 & 166,736 & 18,286,449 \textbf{\textbf{($\simeq$)}} & 163,816 \textbf{\textbf{($\simeq$)}} & 166,736 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{cnn\_s\_quantized}} & 10,817,201 & 191,096 & 34,560 & 8,305,469 \textbf{(-24\%)} & 190,616 \textbf{\textbf{($\simeq$)}} & 34,560 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{toycar}} & 969,032 & 591,256 & 5,400 & 700,731 \textbf{(-28\%)} & 589,752 \textbf{\textbf{($\simeq$)}} & 5,400 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{bigsine\_quant}} & 2,015 & 47,032 & 2,760 & 1,654 \textbf{(-18\%)} & 46,488 \textbf{(-2\%)} & 2,760 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{umatest}} & 2,742,063 & 284,104 & 149,432 & 2,742,418 \textbf{\textbf{($\simeq$)}} & 284,104 \textbf{\textbf{($\simeq$)}} & 149,432 \textbf{\textbf{($\simeq$)}} \\
        \cline{2-7}
        \hline
        {\textbf{simple\_mnist}} & 85,649 & 49,672 & 16,900 & 85,439 \textbf{($\simeq$)} & 49,656 \textbf{($\simeq$)} & 16,900 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{lstm2}} & 1,296 & 46,152 & 3,040 & 1,294 \textbf{($\simeq$)} & 46,152 \textbf{($\simeq$)} & 3,040 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{sine\_model}} & 1,313 & 45,912 & 2,824 & 1,312 \textbf{($\simeq$)} & 45,912 \textbf{($\simeq$)} & 2,824 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{micro\_speech}} & 1,717,354 & 79,752 & 16,660 & 1,375,234 \textbf{(-20\%)} & 79,656 \textbf{($\simeq$)} & 16,660 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{text\_class}} & 43,223 & 687,272 & 20,104 & 43,222 \textbf{($\simeq$)} & 687,272 \textbf{($\simeq$)} & 20,104 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{micro\_kws\_m\_quantized}} & 27,022,276 & 110,792 & 50,912 & 21,210,359 \textbf{(-20\%)} & 110,168 \textbf{($\simeq$)} & 50,912 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{catdog}} & 502,649 & 85,272 & 4,892 & 404,505 \textbf{(-20\%)} & 85,048 \textbf{($\simeq$)} & 4,892 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{aww}} & 21,622,556 & 119,048 & 59,392 & 18,823,597 \textbf{(-13\%)} & 118,360 \textbf{($\simeq$)} & 59,392 \textbf{($\simeq$)} \\
        \cline{2-7}
        \hline
        {\textbf{qnn\_model}} & 610,057 & 249,304 & 12,896 & 463,652 \textbf{(-24\%)} & 248,824 \textbf{($\simeq$)} & 12,896 \textbf{($\simeq$)} \\
        \cline{2-7}

    \end{tabular}
    \caption{Summary of Performance Metrics for Models on ETISS using MLonMCU}
    \label{tab:performance_metrics}
\end{table}

\begin{table}[!hp]
    \footnotesize
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Model} & \textbf{Instruction} & \textbf{Count} & \textbf{Probability} \\ \hline
        \textbf{coremark} & openasip\_base\_shl1add & 60503 & 0.016 \\ \cline{2-4}
                           & openasip\_base\_mac     & 58347 & 0.015 \\ \cline{2-4}
                           & openasip\_base\_shl2add & 19876 & 0.005 \\ \cline{2-4}
                           & openasip\_base\_gt      & 12960 & 0.003 \\ \cline{2-4}
                           & openasip\_base\_maxu    & 41    & 0.0   \\ \hline
        \textbf{magic\_wand} & openasip\_base\_shl2add & 2596 & 0.009 \\ \hline
        \textbf{micro\_kws\_m\_fp32} & openasip\_base\_shl2add & 39300 & 0.002 \\ \cline{2-4}
                                       & openasip\_base\_mac     & 642   & 0.0   \\ \hline
        \textbf{cnn\_s\_quantized} & openasip\_base\_mac     & 535723 & 0.064 \\ \cline{2-4}
                                    & openasip\_base\_shl1add & 11202  & 0.001 \\ \cline{2-4}
                                    & openasip\_base\_min     & 9916   & 0.001 \\ \cline{2-4}
                                    & openasip\_base\_max     & 9916   & 0.001 \\ \cline{2-4}
                                    & openasip\_base\_shl2add & 5778   & 0.001 \\ \hline
        \textbf{toycar} & openasip\_base\_mac     & 266384 & 0.372 \\ \cline{2-4}
                         & openasip\_base\_min     & 1672   & 0.002 \\ \cline{2-4}
                         & openasip\_base\_max     & 1672   & 0.002 \\ \cline{2-4}
                         & openasip\_base\_shl2add & 4      & 0.0   \\ \hline
        \textbf{bigsine\_quant} & openasip\_base\_mac     & 148  & 0.01  \\ \cline{2-4}
                                  & openasip\_base\_max     & 39   & 0.003 \\ \cline{2-4}
                                  & openasip\_base\_min     & 39   & 0.003 \\ \cline{2-4}
                                  & openasip\_base\_shl2add & 4    & 0.0   \\ \hline
        \textbf{umatest} & openasip\_base\_shl2add & 7060  & 0.003 \\ \cline{2-4}
                          & openasip\_base\_mac     & 86    & 0.0   \\ \hline
        \textbf{simple\_mnist} & openasip\_base\_shl2add & 213   & 0.002 \\ \hline
        \textbf{cifar10} & openasip\_base\_shl2add & 129017 & 0.004 \\ \cline{2-4}
                          & openasip\_base\_mac     & 612    & 0.0   \\ \hline
        \textbf{lstm2} & openasip\_base\_shl2add & 5      & 0.0   \\ \hline
        \textbf{sine\_model} & openasip\_base\_shl2add & 4      & 0.0   \\ \hline
        \textbf{micro\_speech} & openasip\_base\_mac     & 344008 & 0.247 \\ \cline{2-4}
                                & openasip\_base\_shl2add & 12504  & 0.009 \\ \cline{2-4}
                                & openasip\_base\_min     & 4004   & 0.003 \\ \cline{2-4}
                                & openasip\_base\_max     & 4004   & 0.003 \\ \cline{2-4}
                                & openasip\_base\_shl1add & 4000   & 0.003 \\ \hline
        \textbf{text\_class} & openasip\_base\_shl2add & 4 & 0.0 \\ \hline
        \textbf{micro\_kws\_m\_quantized} & openasip\_base\_mac     & 5806058 & 0.273 \\ \cline{2-4}
                                            & openasip\_base\_shl2add & 125326  & 0.006 \\ \cline{2-4}
                                            & openasip\_base\_max     & 39098   & 0.002 \\ \cline{2-4}
                                            & openasip\_base\_min     & 39098   & 0.002 \\ \cline{2-4}
                                            & openasip\_base\_shl1add & 33320   & 0.002 \\ \hline
        \textbf{catdog} & openasip\_base\_mac     & 84009  & 0.2   \\ \cline{2-4}
                         & openasip\_base\_shl1add & 2780   & 0.007 \\ \cline{2-4}
                         & openasip\_base\_shl2add & 2104   & 0.005 \\ \cline{2-4}
                         & openasip\_base\_min     & 1901   & 0.005 \\ \cline{2-4}
                         & openasip\_base\_max     & 1901   & 0.005 \\ \hline
        \textbf{aww} & openasip\_base\_mac     & 2228231 & 0.118 \\ \cline{2-4}
                      & openasip\_base\_min     & 72012   & 0.004 \\ \cline{2-4}
                      & openasip\_base\_max     & 72012   & 0.004 \\ \cline{2-4}
                      & openasip\_base\_shl2add & 32129   & 0.002 \\ \cline{2-4}
                      & openasip\_base\_shl1add & 125     & 0.0   \\ \hline
        \textbf{qnn\_model} & openasip\_base\_mac     & 31604  & 0.066 \\ \cline{2-4}
                              & openasip\_base\_min     & 3178   & 0.007 \\ \cline{2-4}
                              & openasip\_base\_max     & 3178   & 0.007 \\ \cline{2-4}
                              & openasip\_base\_shl2add & 816    & 0.002 \\ \hline
    \end{tabular}
    \caption{Summary of Custom Instruction Usage in Models}
    \label{tab:custom_instruction_usage}
\end{table}

\subsection{Instructions Count}
The number of instructions executed is a critical metric, as a reduction typically implies more efficient code execution. For several models, the use of custom instructions resulted in a significant reduction in the total number of instructions executed:

\begin{itemize}
    \item \textbf{cnn\_s\_quantized:} A substantial reduction of 24\% in instructions executed was observed, dropping from 10,817,201 to 8,305,469 instructions. This decrease is primarily due to the use of the \textit{openasip\_base\_mac} instruction, which was executed 535,723 times (6.4\% of the total instructions), along with other custom instructions like \textit{openasip\_base\_shl1add} and \textit{openasip\_base\_max}, which contributed to this optimization.
    \item \textbf{toycar:} The instruction count was reduced by 28\%, going from 969,032 to 700,731. Here, the custom \textit{openasip\_base\_mac} instruction played a significant role, contributing to 37.2\% of the total instructions executed (266,384 times), resulting in the observed performance improvement.
    \item \textbf{micro\_speech:} This model saw a 20\% reduction in instruction count, dropping from 1,717,354 to 1,375,234. The custom instructions used, particularly the \textit{openasip\_base\_mac} (executed 344,008 times, 24.7\% of total instructions) and \textit{openasip\_base\_shl2add} (12,504 executions), greatly contributed to this efficiency.
    \item \textbf{micro\_kws\_m\_quantized:} Another significant improvement was seen with a 20\% reduction, from 27,022,276 to 21,210,359 instructions. This result was driven by extensive use of \textit{openasip\_base\_mac} (5,806,058 executions, 27.3\%) and \textit{openasip\_base\_shl2add}, which accounted for 0.6\% of the total instructions.
    \item \textbf{catdog:} The number of instructions decreased by 20\%, from 502,649 to 404,505. The custom \textit{openasip\_base\_mac} was executed 84,009 times, contributing 20\% to the total instruction count, significantly improving the model's efficiency.
    \item \textbf{aww:} This model saw a 13\% reduction in instruction count, going from 21,622,556 to 18,823,597. The \textit{openasip\_base\_mac} instruction was executed 2,228,231 times (11.8\%), playing a major role in this reduction.
\end{itemize}

In contrast, some models exhibited minimal changes in instruction count:
\begin{itemize}
    \item \textbf{coremark:} There was a small 2\% reduction, from 3,877,413 to 3,805,676 instructions, suggesting that the coremark workload benefits only marginally from custom instructions like \textit{openasip\_base\_shl1add} and \textit{openasip\_base\_mac}.
    \item \textbf{magic\_wand, micro\_kws\_m\_fp32, umatest, simple\_mnist, lstm2, sine\_model:} These models showed negligible differences in instruction count, indicating that their execution patterns are less affected by the specific optimizations introduced through custom instructions.
\end{itemize}

\subsection{ROM and RAM Usage}
ROM and RAM usage are crucial for assessing the memory footprint of the system, especially in embedded applications where memory resources are constrained. The ROM and RAM usage across all models remained almost identical between the baseline and custom instruction configurations. This indicates that the introduction of custom instructions does not introduce additional memory overhead, which is a critical factor in low-power, resource-constrained environments:

\begin{itemize}
    \item For the \textbf{coremark}, \textbf{cnn\_s\_quantized}, \textbf{toycar}, and \textbf{bigsine\_quant} benchmarks, ROM usage remained constant, with slight variations in the order of 0.1\% to 2\%.
    \item RAM usage across all models was unchanged, suggesting that the custom instructions are efficiently integrated without requiring additional data storage or memory allocation.
\end{itemize}

\subsection{Custom Instruction Usage}
Table~\ref{tab:custom_instruction_usage} presents a detailed analysis of the frequency and types of custom instructions used across different models. The custom instructions, particularly \textit{openasip\_base\_mac}, \textit{openasip\_base\_shl1add}, and \textit{openasip\_base\_shl2add}, were the most frequently executed, contributing significantly to performance improvements:

\begin{itemize}
    \item The \textbf{cnn\_s\_quantized} model made extensive use of \textit{openasip\_base\_mac}, which was executed 535,723 times (6.4\% of total instructions). This custom instruction played a crucial role in reducing the overall instruction count by 24\%.
    \item In the \textbf{toycar} model, \textit{openasip\_base\_mac} accounted for 37.2\% of total instructions, making it the most frequently used custom instruction in this benchmark, explaining the significant 28\% reduction in instruction count.
    \item The \textbf{micro\_kws\_m\_quantized} model saw the most usage of \textit{openasip\_base\_mac}, executed 5,806,058 times (27.3\%). This heavy reliance on the custom instruction led to a 20\% reduction in instruction count.
\end{itemize}

Overall, custom instructions contributed to substantial reductions in instruction counts for a range of models, particularly those involving quantized neural networks (e.g., \textbf{cnn\_s\_quantized}, \textbf{toycar}, \textbf{micro\_speech}). For other models, like \textbf{coremark} and \textbf{magic\_wand}, the performance improvements were less pronounced, indicating that the custom instruction set is more beneficial for specific workloads.

\section{Discussion}

The performance results indicate that the custom instructions provided modest improvements in reducing the number of executed instructions and clock cycles. For instance, in the \textbf{cifar10} model, the use of custom operations such as \textbf{openasip\_base\_shl2add} and \textbf{openasip\_base\_mac} contributed to significant reductions in execution time by optimizing certain arithmetic operations.

Across various models, the custom instructions were frequently executed, demonstrating their utility in different machine learning workloads. The LLVM backend generated by Seal5 was successfully integrated with MLonMCU, and the benchmarking process revealed that the custom instruction set can optimize specific computational tasks, particularly those involving shifts and multiplications.

Although the performance gains observed were moderate, this evaluation demonstrates the potential for custom operations to optimize specific computational workloads. Further tests will be conducted using additional machine learning models, which are expected to highlight more substantial improvements in performance across a broader range of applications.