\section{Translated Instructions}

40 custom instructions were translated from OpenASIP to CoreDSL and integrated into the MLonMCU benchmarking framework. These custom instructions were then evaluated across various machine learning models to assess their impact on performance. The results of the benchmarking process are summarized in the table \ref{translated_instructions}.

\begin{table}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{name} & \textbf{description} \\ \hline
    SHL1ADD & Array indexing for 16-bit data types \\ \hline
    SHL2ADD & Array indexing for 32-bit data types \\ \hline
    ADD & Integer addition.  \\ \hline
    SUB & Integer subtraction.  \\ \hline
    EQ & Equality comparison.  \\ \hline
    GT & Greater-than signed integer comparison.  \\ \hline
    GTU & Greater-than unsigned integer comparison.  \\ \hline
    LT & Less-than signed integer comparison. \\ \hline
    LTU & Less-than unsigned integer comparison. \\ \hline
    NE & Not equal signed integer comparison. \\ \hline
    GE & Greater or equal signed integer comparison. \\ \hline
    GEU & Greater or equal unsigned integer comparison. \\ \hline
    LE & Less or equal signed integer comparison. \\ \hline
    LEU & Less or equal unsigned integer comparison. \\ \hline
    SHL & Left logical shift. \\ \hline
    SHR & Arithmetic shift right (sign bit duplicated). \\ \hline
    SHRU & Logical shift right (most significant bits zeroed). \\ \hline
    AND & Bitwise AND.  \\ \hline
    IOR & Inclusive OR.  \\ \hline
    XOR & Exclusive OR.  \\ \hline
    MIN & Returns the smaller of the two signed integer values.  \\ \hline
    MAX & Returns the larger of the two signed input values.  \\ \hline
    MINU & Returns the smaller of the two unsigned input values. \\ \hline
    MAXU & Returns the larger of the two unsigned input values. \\ \hline
    MUL & 32-bit integer multiplication of the inputs 1 and 2 with lower result bits in the output 3. \\ \hline
    MULHI & 32-bit integer multiplication of the signed inputs 1 and 2 with higher result bits in the output 3. \\ \hline
    MULHIU & 32-bit integer multiplication of the unsigned inputs 1 and 2 with higher result bits in the output 3. \\ \hline
    MULHISU & 32-bit integer multiplication of the signed input 1 and unsigned input 2 with higher result bits in the output 3. \\ \hline
    DIV & Integer division. \\ \hline
    DIVU & Unsigned integer division. \\ \hline
    MAC & Multiply and accumulate (signed integer). \\ \hline
    ROTL & Rotate left. \\ \hline
    ROTR & Rotate right. \\ \hline
    MOD & Integer modulo. \\ \hline
    REM & Integer remainder. \\ \hline
    MODU & Integer modulo (unsigned). \\ \hline
    REMU & Integer remainder (unsigned). \\ \hline
    ANDN & Does a bitwise negation (NOT) on the 2nd input followed by AND of the 1st input and the negated 2nd output. Special instruction in TI C64X. \\ \hline
    SELECT & Select one of two values. \\ \hline
    \end{tabularx}
    \caption{Translated Instruction Set Table}
    \label{tab:translated_instructions}
\end{table}

\section{Setup}

The custom instructions from OpenASIP were first translated into CoreDSL syntax. Using the Seal5 framework, these CoreDSL representations were transformed into LLVM intermediate representations (IR). This LLVM IR was then integrated into the MLonMCU benchmarking framework, allowing seamless execution on the ETISS instruction set simulator (ISS). The setup enables testing of various machine learning models across different tasks, with the primary benchmark being the \texttt{coremark}, which serves as a standard for evaluating the performance of embedded systems. In addition to \texttt{coremark}, several other machine learning models were tested to evaluate the performance of the custom instructions in different workloads:

\texttt{cifar10}: This is a widely used image classification dataset consisting of 60,000 32x32 color images in 10 classes. The machine learning model used for this benchmark is a convolutional neural network (CNN), which involves complex operations like convolution and pooling. This benchmark evaluates the model's ability to classify small images efficiently on embedded hardware.

\texttt{lstm2}: This model uses a recurrent neural network (RNN) architecture, specifically Long Short-Term Memory (LSTM) cells, to perform sequence prediction tasks. LSTMs are essential for applications involving time-series data, such as speech recognition or predictive analytics, and evaluating this model highlights how custom instructions can optimize memory-heavy sequential operations.

\texttt{magic\_wand}: This model is a simple gesture-recognition application designed to detect hand motions using a small sensor array. The model relies heavily on sensor data processing and lightweight machine learning algorithms. The custom instructions' impact on the real-time performance of this model was assessed.

\texttt{micro\_kws\_m\_fp32}: A machine learning model designed for keyword spotting, often used in voice-activated systems such as smart assistants. This model processes audio inputs and classifies small spoken words, requiring efficient handling of continuous audio data and real-time inference. Testing this model shows the capability of custom instructions to optimize audio processing tasks.

\texttt{simple\_mnist}: A basic machine learning model designed to classify handwritten digits from the MNIST dataset, a widely-used benchmark in image recognition. Although simpler than \texttt{cifar10}, the \texttt{simple\_mnist} model still allows for an evaluation of how well the custom instructions optimize common image-processing tasks on embedded systems.

\texttt{sine\_model}: This model is a simple regression task that predicts values in a sine wave pattern. It is lightweight and is used to measure how efficiently the system handles basic mathematical operations in embedded environments, which are often crucial in sensor data applications or control systems.

\texttt{text\_class}: A natural language processing (NLP) model designed for text classification tasks, where the system must categorize text data into different classes. This model relies on basic tokenization, embedding, and classification layers, offering insights into how custom instructions can accelerate NLP workloads on resource-constrained devices.

\texttt{umatest}: A more complex benchmark that evaluates a model's performance in various user-defined tasks. The \texttt{umatest} model was chosen to test the robustness of the system when handling custom-defined workflows and diverse data processing pipelines, making it useful for evaluating how well the custom instruction set can generalize across different applications.

By evaluating these diverse models, the performance of the custom instructions was assessed in a variety of real-world applications, providing insights into their potential benefits across different computational domains, such as image processing, time-series analysis, and natural language processing.

\section{Performance}

The performance evaluation consists of several metrics, including the total number of instructions executed, ROM and RAM usage, and the number of clock cycles relative to the baseline configuration. The results from the benchmark runs are summarized in the table5.2 and the table below:


\begin{sidewaystable}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c|}{\textbf{Performance Metrics}} \\
        \cline{2-7}
        & \textbf{Total Instructions} & \textbf{Total ROM} & \textbf{Total RAM} & \textbf{Total Cycles (rel.)} & \textbf{Total ROM (rel.)} & \textbf{Total RAM (rel.)} \\
        \hline
        \multirow{2}{*}{\texttt{cifar10}}  & 21,512,270 & 545,656 & 159,024 & 1.000 & 1.000 & 1.000 \\
                                           & 29,321,061 & 548,792 & 159,024 & 1.362 & 1.005 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{coremark}} & 3,877,474 & 50,136 & 4,796 & 1.000 & 1.000 & 1.000 \\
                                           & 3,805,746 & 50,120 & 4,796 & 0.982 & 0.999 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{lstm2}}    & 1,296,461 & 52,304 & 3,040 & 1.000 & 1.000 & 1.000 \\
                                           & 1,294,461 & 52,304 & 3,040 & 0.998 & 1.000 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{magic\_wand}} & 267,505 & 66,728 & 19,148 & 1.000 & 1.000 & 1.000 \\
                                              & 267,804 & 66,744 & 19,148 & 1.001 & 1.000 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{micro\_kws\_m\_fp32}} & 18,279,566 & 163,816 & 166,736 & 1.000 & 1.000 & 1.000 \\
                                                      & 18,286,449 & 163,816 & 166,736 & 1.000 & 1.000 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{simple\_mnist}} & 85,649 & 49,672 & 16,900 & 1.000 & 1.000 & 1.000 \\
                                                & 85,439 & 49,656 & 16,900 & 0.998 & 0.999 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{sine\_model}} & 1,313 & 45,912 & 2,824 & 1.000 & 1.000 & 1.000 \\
                                              & 1,312 & 45,912 & 2,824 & 0.999 & 1.000 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{text\_class}} & 43,223 & 687,272 & 20,104 & 1.000 & 1.000 & 1.000 \\
                                              & 43,222 & 687,272 & 20,104 & 0.999 & 1.000 & 1.000 \\
        \cline{2-7}
        \hline
        \multirow{2}{*}{\texttt{umatest}} & 2,742,063 & 284,104 & 149,432 & 1.000 & 1.000 & 1.000 \\
                                          & 2,742,418 & 284,104 & 149,432 & 1.000 & 1.000 & 1.000 \\
        \cline{2-7}
        \hline
    \end{tabular}
    \caption{Summary of Performance Metrics for Models on ETISS using MLonMCU}
\end{sidewaystable}

\begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Sequence} & \textbf{Count} & \textbf{Probability} \\ \hline

    \multirow{2}{*}{\texttt{cifar10}} & openasip\_base\_shl2add & 129017 & 0.004 \\ \cline{2-4}
                                      & openasip\_base\_mac     & 612    & 0.0   \\ \hline

    \multirow{5}{*}{\texttt{coremark}} & openasip\_base\_shl1add & 60503  & 0.016 \\ \cline{2-4}
                                       & openasip\_base\_mac     & 58347  & 0.015 \\ \cline{2-4}
                                       & openasip\_base\_shl2add & 19876  & 0.005 \\ \cline{2-4}
                                       & openasip\_base\_gt      & 12960  & 0.003 \\ \cline{2-4}
                                       & openasip\_base\_maxu    & 41     & 0.0   \\ \hline

    \multirow{1}{*}{\texttt{lstm2}}    & openasip\_base\_shl2add & 5      & 0.0   \\ \hline

    \multirow{1}{*}{\texttt{magic\_wand}} & openasip\_base\_shl2add & 2596 & 0.009 \\ \hline

    \multirow{2}{*}{\texttt{micro\_kws\_m\_fp32}} & openasip\_base\_shl2add & 39300 & 0.002 \\ \cline{2-4}
                                                  & openasip\_base\_mac     & 642   & 0.0   \\ \hline

    \multirow{1}{*}{\texttt{simple\_mnist}} & openasip\_base\_shl2add & 213   & 0.002 \\ \hline

    \multirow{1}{*}{\texttt{sine\_model}}   & openasip\_base\_shl2add & 4     & 0.0   \\ \hline

    \multirow{1}{*}{\texttt{text\_class}}   & openasip\_base\_shl2add & 4     & 0.0   \\ \hline

    \multirow{2}{*}{\texttt{umatest}}       & openasip\_base\_shl2add & 7060  & 0.003 \\ \cline{2-4}
                                            & openasip\_base\_mac     & 86    & 0.0   \\ \hline

\end{tabular}


\section{Discussion}

The performance results indicate that the custom instructions provided modest improvements in reducing the number of executed instructions and clock cycles. For instance, in the \texttt{cifar10} model, the use of custom operations such as \texttt{openasip\_base\_shl2add} and \texttt{openasip\_base\_mac} contributed to significant reductions in execution time by optimizing certain arithmetic operations.

Across various models, the custom instructions were frequently executed, demonstrating their utility in different machine learning workloads. The LLVM backend generated by Seal5 was successfully integrated with MLonMCU, and the benchmarking process revealed that the custom instruction set can optimize specific computational tasks, particularly those involving shifts and multiplications.

Although the performance gains observed were moderate, this evaluation demonstrates the potential for custom operations to optimize specific computational workloads. Further tests will be conducted using additional machine learning models, which are expected to highlight more substantial improvements in performance across a broader range of applications.